from typing import List
import requests
import ollama

class DeepSeekModel:

    @staticmethod
    def generate_syllabus(course_title, abstract_info):
        """
        Use DeepSeek-R1 model to generate a syllabus based on course title and abstract info.
        """
        my_model = "tinyllama:latest"
        my_prompt = f"Generate a concise course description for a Rutgers course titled '{course_title}'. Here's some background information: {abstract_info}"
        
        try:
            # Interact with the DeepSeek-R1 model via Ollama
            response = ollama.generate(
                model=my_model, 
                prompt=my_prompt,
                #options={"num_tokens": 200}
                )
        
            # Extract only the response text
            if response and "response" in response:
                return response["response"]
            else:
                print("No response generated by the model.")
                return None
        except Exception as e:
            print(f"Error generating syllabus with Ollama: {e}")
            return None